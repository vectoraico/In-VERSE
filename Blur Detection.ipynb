{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34cb56ba-8526-4f4c-b75e-361212eb46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def calculate_laplacian_variance(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "def blur_detect_DIP(image_path):\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    threshhold = 100\n",
    "    laplacian_var = calculate_laplacian_variance(image)\n",
    "    \n",
    "    if laplacian_var < threshhold:\n",
    "        return \"blur\"\n",
    "    else:\n",
    "        return \"sharp\"\n",
    "\n",
    "def classify_image(image_path, model):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = transform(Image.open(image_path)).unsqueeze(0)\n",
    "    features = feature_extractor(image)\n",
    "    outputs = classifier(features)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    return predicted.item()\n",
    "\n",
    "def blur_detect_ML(image_path):\n",
    "    class FeatureExtractor(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(FeatureExtractor, self).__init__()\n",
    "            self.resnet = models.resnet18(pretrained=True)\n",
    "            self.resnet.fc = nn.Identity() \n",
    "    \n",
    "        def forward(self, x):\n",
    "            return self.resnet(x)\n",
    "    \n",
    "    #Setting up a shallow Fully Connected Classifier\n",
    "    class Classifier(nn.Module):\n",
    "        def __init__(self, input_size, num_classes):\n",
    "            super(Classifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = torch.flatten(x, 1)  # Flatten the features\n",
    "            x = nn.functional.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    feature_extractor = FeatureExtractor()\n",
    "    classifier = Classifier(512, 3)\n",
    "    model = nn.Sequential(feature_extractor, classifier)\n",
    "    \n",
    "    #Loading our trained model\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    #Defining an inference method for custom images\n",
    "    def classify_image(image_path, model):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(Image.open(image_path)).unsqueeze(0)\n",
    "        features = feature_extractor(image)\n",
    "        outputs = classifier(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted.item()\n",
    "    \n",
    "    #Mapping the class index - To Category\n",
    "    category = {0: \"blur\", 1: \"blur\", 2: \"sharp\"}\n",
    "    image_path = 'img1.jpeg'\n",
    "    class_index = classify_image(image_path, model)\n",
    "    return category[class_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4c223b3-41ce-49db-b534-b20e2a5bbf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_blur(image_path):\n",
    "    DIP = blur_detect_DIP(image_path)\n",
    "    ML = blur_detect_ML(image_path)\n",
    "\n",
    "    if (DIP == \"sharp\" and ML == \"sharp\"):\n",
    "        return \"sharp\"\n",
    "\n",
    "    if (DIP == \"blur\" and ML == \"blur\"):\n",
    "        return \"blur\"\n",
    "\n",
    "    return blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3168ecb-3a42-458b-a9a5-3f07ac356f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab89c00-02fc-4a19-81d9-2e39a6fa601f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

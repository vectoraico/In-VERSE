{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34cb56ba-8526-4f4c-b75e-361212eb46ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def calculate_laplacian_variance(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "\n",
    "def blur_detect_DIP(image_path):\n",
    "\n",
    "    image = cv2.imread(image_path)\n",
    "    threshhold = 100\n",
    "    laplacian_var = calculate_laplacian_variance(image)\n",
    "    \n",
    "    if laplacian_var < threshhold:\n",
    "        return \"blur\"\n",
    "    else:\n",
    "        return \"sharp\"\n",
    "\n",
    "def blur_detect_ML(image_path):\n",
    "    class FeatureExtractor(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(FeatureExtractor, self).__init__()\n",
    "            self.resnet = models.resnet18(pretrained=True)\n",
    "            self.resnet.fc = nn.Identity() \n",
    "    \n",
    "        def forward(self, x):\n",
    "            return self.resnet(x)\n",
    "    \n",
    "    #Setting up a shallow Fully Connected Classifier\n",
    "    class Classifier(nn.Module):\n",
    "        def __init__(self, input_size, num_classes):\n",
    "            super(Classifier, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_size, 128)\n",
    "            self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "        def forward(self, x):\n",
    "            x = torch.flatten(x, 1)  # Flatten the features\n",
    "            x = nn.functional.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "            return x\n",
    "    \n",
    "    feature_extractor = FeatureExtractor()\n",
    "    classifier = Classifier(512, 3)\n",
    "    model = nn.Sequential(feature_extractor, classifier)\n",
    "    \n",
    "    #Loading our trained model\n",
    "    model.load_state_dict(torch.load('model.pth'))\n",
    "    model.eval()\n",
    "    \n",
    "    #Defining an inference method for custom images\n",
    "    def classify_image(image_path, model):\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        image = transform(Image.open(image_path)).unsqueeze(0)\n",
    "        features = feature_extractor(image)\n",
    "        outputs = classifier(features)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        return predicted.item()\n",
    "    \n",
    "    #Mapping the class index - To Category\n",
    "    category = {0: \"blur\", 1: \"blur\", 2: \"sharp\"}\n",
    "    # image_path = 'img1.jpeg'\n",
    "    \n",
    "    class_index = classify_image(image_path, model)\n",
    "    return category[class_index]\n",
    "\n",
    "def detect_blur(image_path):\n",
    "    DIP = blur_detect_DIP(image_path)\n",
    "    ML = blur_detect_ML(image_path)\n",
    "\n",
    "    if (DIP == \"sharp\" and ML == \"sharp\"):\n",
    "        return True\n",
    "\n",
    "    if (DIP == \"blur\" and ML == \"blur\"):\n",
    "        return False\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4c223b3-41ce-49db-b534-b20e2a5bbf5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3168ecb-3a42-458b-a9a5-3f07ac356f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abdulwadood/anaconda3/envs/InVerse/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/abdulwadood/anaconda3/envs/InVerse/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/abdulwadood/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:03<00:00, 11.7MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = '/Users/abdulwadood/Downloads/Archive 2/FYP Final/ErrorChecking/BlurDetection/img1.jpeg'\n",
    "detect_blur(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab89c00-02fc-4a19-81d9-2e39a6fa601f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
